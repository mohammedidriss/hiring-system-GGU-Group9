{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM73EwSEcUB5jnU4KVLQKPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedidriss/hiring-system-GGU-Group9/blob/main/Advanced_ROI_Calculator_for_AI_Hiring_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "Ia3RXlTl29sL",
        "outputId": "c584f44f-a43b-4dfc-a644-bf96f0e089be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1642509942.py:250: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://40e25d5a0a2a704df7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://40e25d5a0a2a704df7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. EXPERT PRICING DATABASE (2025 Estimates) ---\n",
        "# Costs are normalized to hourly or monthly rates.\n",
        "\n",
        "PRICING_DB = {\n",
        "    \"AWS Native\": {\n",
        "        \"compute_hourly\": 0.096,    # m5.large (2 vCPU)\n",
        "        \"gpu_hourly\": 0.0,          # Uses API, not raw GPU\n",
        "        \"storage_gb_mo\": 0.023,     # S3 Standard\n",
        "        \"ai_input_token\": 3.00,     # Claude 3.5 Sonnet ($3/1M input)\n",
        "        \"ai_output_token\": 15.00,   # Claude 3.5 Sonnet ($15/1M output)\n",
        "        \"platform_fee_hourly\": 0.0,\n",
        "        \"net_ops_overhead\": 0.12,   # 12% for NAT, LB, WAF, Egress\n",
        "        \"devops_scale\": 1.0         # Baseline Ops\n",
        "    },\n",
        "    \"Azure Native\": {\n",
        "        \"compute_hourly\": 0.096,    # D2s v3\n",
        "        \"gpu_hourly\": 0.0,\n",
        "        \"storage_gb_mo\": 0.019,     # ADLS Gen2\n",
        "        \"ai_input_token\": 2.50,     # GPT-4o ($2.50/1M input)\n",
        "        \"ai_output_token\": 10.00,   # GPT-4o ($10.00/1M output)\n",
        "        \"platform_fee_hourly\": 0.0,\n",
        "        \"net_ops_overhead\": 0.12,\n",
        "        \"devops_scale\": 1.0\n",
        "    },\n",
        "    \"GCP Native\": {\n",
        "        \"compute_hourly\": 0.085,    # n2-standard-2\n",
        "        \"gpu_hourly\": 0.0,\n",
        "        \"storage_gb_mo\": 0.020,     # GCS\n",
        "        \"ai_input_token\": 1.25,     # Gemini 1.5 Pro ($1.25/1M input)\n",
        "        \"ai_output_token\": 5.00,    # Gemini 1.5 Pro ($5.00/1M output)\n",
        "        \"platform_fee_hourly\": 0.0,\n",
        "        \"net_ops_overhead\": 0.12,\n",
        "        \"devops_scale\": 1.0\n",
        "    },\n",
        "    \"ROSA (AWS)\": {\n",
        "        \"compute_hourly\": 0.096,    # Underlying EC2\n",
        "        \"gpu_hourly\": 1.50,         # g5.4xlarge (Hosting Llama 3)\n",
        "        \"storage_gb_mo\": 0.023,     # S3 for Data Lake\n",
        "        \"ai_input_token\": 0.0,      # Self-Hosted (Cost is in GPU)\n",
        "        \"ai_output_token\": 0.0,\n",
        "        \"platform_fee_hourly\": 0.171, # ROSA Service Fee (4vCPU)\n",
        "        \"net_ops_overhead\": 0.08,   # Slightly lower egress profile\n",
        "        \"devops_scale\": 1.2         # K8s Mgmt\n",
        "    },\n",
        "    \"ARO (Azure)\": {\n",
        "        \"compute_hourly\": 0.126,    # VM + ARO bundled\n",
        "        \"gpu_hourly\": 1.60,         # NC Series\n",
        "        \"storage_gb_mo\": 0.019,     # ADLS\n",
        "        \"ai_input_token\": 0.0,\n",
        "        \"ai_output_token\": 0.0,\n",
        "        \"platform_fee_hourly\": 0.0, # Included in compute rate usually\n",
        "        \"net_ops_overhead\": 0.08,\n",
        "        \"devops_scale\": 1.2\n",
        "    },\n",
        "    \"Self-Managed OCP\": {\n",
        "        \"compute_hourly\": 0.050,    # Amortized Bare Metal\n",
        "        \"gpu_hourly\": 0.90,         # Amortized GPU Hardware\n",
        "        \"storage_gb_mo\": 0.040,     # ODF/Ceph (3x replication)\n",
        "        \"ai_input_token\": 0.0,\n",
        "        \"ai_output_token\": 0.0,\n",
        "        \"platform_fee_hourly\": 0.06,# Red Hat Subscription\n",
        "        \"net_ops_overhead\": 0.25,   # Power, Cooling, DC Networking\n",
        "        \"devops_scale\": 2.5         # Heavy Ops Load\n",
        "    }\n",
        "}\n",
        "\n",
        "# Annual Salaries (Fully Burdened)\n",
        "LABOR_COSTS = {\n",
        "    \"Data Scientist\": 175000,\n",
        "    \"ML Engineer\": 170000,\n",
        "    \"DevOps Engineer\": 165000,\n",
        "    \"Project Manager\": 145000\n",
        "}\n",
        "\n",
        "# --- 2. CALCULATION ENGINE ---\n",
        "\n",
        "def calculate_granular_roi(\n",
        "    candidates, recruiters, salary, hours_saved, retention,\n",
        "    n_ds, n_ml, n_devops, n_pm,\n",
        "    agency_cost_savings, churn_cost_savings\n",
        "):\n",
        "    results = [] # Initialized to an empty list\n",
        "\n",
        "    # --- SIZING HEURISTICS ---\n",
        "    # 1. Compute Load (App Layer)\n",
        "    # 1 vCPU per 50 users. Min 2 nodes for HA.\n",
        "    # Hours = 730 per month.\n",
        "    app_nodes = max(2, int(recruiters / 50))\n",
        "    compute_hours_total = app_nodes * 730\n",
        "\n",
        "    # 2. Storage Load\n",
        "    # 5MB per candidate (Resume + JSON + Embeddings + Logs)\n",
        "    # Corrected: 0.005 represents 5MB in GB (5MB / 1000MB/GB). Removed extra *1000.\n",
        "    storage_gb = candidates * 12 * retention * 0.005\n",
        "\n",
        "    # 3. AI Load (GenAI)\n",
        "    # Assumptions: 20 queries/day/recruiter. 2k input tokens, 500 output tokens per query.\n",
        "    queries_mo = recruiters * 20 * 22 # 22 working days\n",
        "    tok_in_mil = (queries_mo * 2000) / 1_000_000\n",
        "    tok_out_mil = (queries_mo * 500) / 1_000_000\n",
        "\n",
        "    # Self-Hosted GPU Load (for OpenShift)\n",
        "    # 2x GPUs running 24/7 for HA Inference\n",
        "    gpu_hours_total = 2 * 730\n",
        "\n",
        "    # 4. Business Value (3 Years)\n",
        "    # Value from recruiter efficiency\n",
        "    hourly_rate = salary / 2080\n",
        "    monthly_value_recruiter_efficiency = recruiters * hours_saved * 4.33 * hourly_rate\n",
        "\n",
        "    # Total value from all sources over 3 years\n",
        "    total_value_3yr = (\n",
        "        monthly_value_recruiter_efficiency * 36 +\n",
        "        agency_cost_savings * 3 +\n",
        "        churn_cost_savings * 3\n",
        "    )\n",
        "\n",
        "    # --- COST CALCULATION LOOP ---\n",
        "    for platform, prices in PRICING_DB.items():\n",
        "        # A. Labor Cost\n",
        "        # DevOps scales with complexity factor\n",
        "        ops_fte = n_devops * prices[\"devops_scale\"]\n",
        "        annual_labor = (\n",
        "            (n_ds * LABOR_COSTS[\"Data Scientist\"]) + # Corrected dictionary access\n",
        "            (n_ml * LABOR_COSTS[\"ML Engineer\"]) +\n",
        "            (ops_fte * LABOR_COSTS[\"DevOps Engineer\"]) + # Corrected dictionary access\n",
        "            (n_pm * LABOR_COSTS[\"Project Manager\"])\n",
        "        )\n",
        "        labor_3yr = annual_labor * 3\n",
        "\n",
        "        # B. App Compute Cost (Application Layer)\n",
        "        cost_compute_mo = compute_hours_total * prices[\"compute_hourly\"]\n",
        "\n",
        "        # C. AI Cost (LLM API vs GPU Infra)\n",
        "        if \"Native\" in platform:\n",
        "            # API Cost\n",
        "            cost_ai_mo = (tok_in_mil * prices[\"ai_input_token\"]) + \\\n",
        "                         (tok_out_mil * prices[\"ai_output_token\"])\n",
        "            gpu_cost_mo = 0\n",
        "        else:\n",
        "            # Self-Hosted GPU Cost\n",
        "            cost_ai_mo = 0 # No token fee\n",
        "            gpu_cost_mo = gpu_hours_total * prices[\"gpu_hourly\"]\n",
        "\n",
        "        # D. Storage Cost\n",
        "        cost_storage_mo = storage_gb * prices[\"storage_gb_mo\"]\n",
        "\n",
        "        # E. Platform Fees (Licensing)\n",
        "        # Fees usually apply to all cores (App + GPU nodes)\n",
        "        total_cores = (app_nodes * 4) + (2 * 16) # Approx core count\n",
        "        cost_fees_mo = total_cores * 730 * (prices[\"platform_fee_hourly\"] / 4) # Normalize fee\n",
        "\n",
        "        # F. Networking & Operations Overhead\n",
        "        # Calculated as % of raw infrastructure\n",
        "        raw_infra = cost_compute_mo + gpu_cost_mo + cost_storage_mo + cost_fees_mo\n",
        "        cost_net_mo = raw_infra * prices[\"net_ops_overhead\"]\n",
        "\n",
        "        # G. Aggregation (3 Years)\n",
        "        # Note: 'App Layer' in chart will include Compute. 'AI Layer' includes API or GPU.\n",
        "\n",
        "        tco_compute = cost_compute_mo * 36\n",
        "        tco_ai = (cost_ai_mo + gpu_cost_mo) * 36\n",
        "        tco_storage = cost_storage_mo * 36\n",
        "        tco_fees = cost_fees_mo * 36\n",
        "        tco_net = cost_net_mo * 36\n",
        "\n",
        "        total_tco_3yr = labor_3yr + tco_compute + tco_ai + tco_storage + tco_fees + tco_net\n",
        "        net_profit = total_value_3yr - total_tco_3yr\n",
        "        roi = (net_profit / total_tco_3yr) * 100 if total_tco_3yr != 0 else 0 # Avoid division by zero\n",
        "\n",
        "        results.append({\n",
        "            \"Platform\": platform,\n",
        "            \"Labor\": round(labor_3yr),\n",
        "            \"App Compute\": round(tco_compute),\n",
        "            \"AI Layer (LLM/GPU)\": round(tco_ai),\n",
        "            \"Storage\": round(tco_storage),\n",
        "            \"Platform Fees\": round(tco_fees),\n",
        "            \"Networking & Ops\": round(tco_net),\n",
        "            \"Total TCO\": round(total_tco_3yr),\n",
        "            \"Net Profit\": round(net_profit),\n",
        "            \"ROI %\": round(roi, 1)\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # --- PLOTTING ---\n",
        "\n",
        "    # 1. Stacked Bar Chart (Granular Cost Breakdown)\n",
        "    fig1, ax1 = plt.subplots(figsize=(12, 7))\n",
        "    platforms = df[\"Platform\"]\n",
        "\n",
        "    # Define layers for stacking\n",
        "    layers = [\"Labor\", \"App Compute\", \"AI Layer (LLM/GPU)\", \"Storage\", \"Platform Fees\", \"Networking & Ops\"]\n",
        "    # Define specific colors for each layer\n",
        "    colors = [\"#2C3E50\", \"#3498DB\", \"#E74C3C\", \"#2ECC71\", \"#F1C40F\", \"#95A5A6\"]\n",
        "\n",
        "    bottom_y = np.zeros(len(platforms))\n",
        "\n",
        "    for i, layer in enumerate(layers):\n",
        "        ax1.bar(platforms, df[layer], bottom=bottom_y, label=layer, color=colors[i], alpha=0.9, width=0.6)\n",
        "        bottom_y += df[layer]\n",
        "\n",
        "    ax1.set_title(\"3-Year Granular TCO Breakdown ($)\", fontsize=14, fontweight='bold')\n",
        "    ax1.set_ylabel(\"Cost (USD)\", fontsize=12)\n",
        "    ax1.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
        "    ax1.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Add Total Labels\n",
        "    for i, total in enumerate(df[\"Total TCO\"]):\n",
        "        ax1.text(i, total, f\"${total/1e6:.1f}M\", ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 2. ROI Bar Chart\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "    roi_colors = ['green' if x > 0 else 'red' for x in df[\"ROI %\"]] # Corrected definition\n",
        "    bars = ax2.bar(platforms, df[\"ROI %\"], color=roi_colors, alpha=0.85) # Used 'ROI %' column\n",
        "\n",
        "    ax2.set_title(\"3-Year Return on Investment (ROI) %\", fontsize=14, fontweight='bold')\n",
        "    ax2.set_ylabel(\"ROI Percentage\", fontsize=12)\n",
        "    ax2.axhline(0, color='black', linewidth=1)\n",
        "    ax2.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                 f'{height:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Formatted Data Table\n",
        "    display_df = df.copy()\n",
        "    format_cols = [\"Labor\", \"App Compute\", \"AI Layer (LLM/GPU)\", \"Storage\", \"Platform Fees\", \"Networking & Ops\", \"Total TCO\", \"Net Profit\"] # Defined columns for formatting\n",
        "    for col in format_cols:\n",
        "        if col in display_df.columns:\n",
        "            display_df[col] = display_df[col].apply(lambda x: f\"${x:,.0f}\")\n",
        "    display_df[\"ROI %\"] = display_df[\"ROI %\"].apply(lambda x: f\"{x}%\") # Apply only to ROI column\n",
        "\n",
        "    return display_df, fig1, fig2\n",
        "\n",
        "# --- UI SETUP ---\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üìä Granular AI Cloud ROI Calculator\")\n",
        "    gr.Markdown(\"Compare **Labor, Infrastructure, AI Tokens, and Licensing Costs** across AWS, Azure, GCP, and OpenShift.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### üè¢ Scale Parameters\")\n",
        "            candidates = gr.Slider(10000, 250000, value=50000, step=5000, label=\"Monthly Candidates\")\n",
        "            recruiters = gr.Slider(50, 1500, value=500, step=50, label=\"Recruiters (Users)\")\n",
        "            retention = gr.Slider(1, 10, value=5, label=\"Data Retention (Years)\")\n",
        "\n",
        "            gr.Markdown(\"### üí∞ Value Drivers\")\n",
        "            salary = gr.Number(value=90000, label=\"Avg Recruiter Salary ($)\")\n",
        "            hours = gr.Slider(1, 10, value=4, label=\"Hours Saved / Week\")\n",
        "            agency_cost_savings = gr.Number(value=500000, label=\"Annual Agency Cost Savings ($)\", info=\"Estimated annual savings from reduced reliance on external agencies due to AI.\")\n",
        "            churn_cost_savings = gr.Number(value=250000, label=\"Annual Employee Churn Cost Savings ($)\", info=\"Estimated annual savings from AI improving hire quality and reducing employee turnover.\")\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### üë∑ Team Composition\")\n",
        "            gr.Markdown(\"*Note: DevOps headcount scales automatically for Self-Managed platforms.*\")\n",
        "            n_ds = gr.Number(value=2, label=\"Data Scientists\")\n",
        "            n_ml = gr.Number(value=2, label=\"ML Engineers\")\n",
        "            n_devops = gr.Number(value=2, label=\"DevOps Engineers (Base)\")\n",
        "            n_pm = gr.Number(value=1, label=\"Project Managers\")\n",
        "\n",
        "            btn = gr.Button(\"üöÄ Calculate Detailed TCO\", variant=\"primary\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"üìâ Visual Analysis\"):\n",
        "            gr.Markdown(\"### Cost & ROI Breakdown\")\n",
        "            with gr.Row():\n",
        "                plot_cost = gr.Plot(label=\"Granular Cost Breakdown\")\n",
        "            with gr.Row():\n",
        "                plot_roi = gr.Plot(label=\"ROI Comparison\")\n",
        "\n",
        "        with gr.TabItem(\"üìã Detailed Data\"):\n",
        "            table_output = gr.DataFrame(label=\"Financials (3-Year Horizon)\")\n",
        "\n",
        "    btn.click(\n",
        "        calculate_granular_roi,\n",
        "        inputs=[candidates, recruiters, salary, hours, retention, n_ds, n_ml, n_devops, n_pm, agency_cost_savings, churn_cost_savings],\n",
        "        outputs=[table_output, plot_cost, plot_roi]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    }
  ]
}