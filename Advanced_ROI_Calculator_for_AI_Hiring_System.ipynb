{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6n/8XHTHSQ1NrWsDjJmTx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedidriss/hiring-system-GGU-Group9/blob/main/Advanced_ROI_Calculator_for_AI_Hiring_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "Ia3RXlTl29sL",
        "outputId": "4d0634c2-c845-4f6b-b517-7594e7a28bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1956579819.py:215: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11a17d8b77b945a821.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://11a17d8b77b945a821.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. CONFIGURATION & PRICING DATABASE (2024/2025 Estimates) ---\n",
        "\n",
        "# Infrastructure Unit Costs (Hourly/Monthly)\n",
        "PRICING_DB = {\n",
        "    \"AWS Native\": {\n",
        "        \"compute\": 0.096,   # m5.large (2 vCPU)\n",
        "        \"gpu\": 0.526,       # g4dn.xlarge (T4)\n",
        "        \"storage\": 0.023,   # S3 Standard\n",
        "        \"ai_token\": 0.015,  # Bedrock/Claude (Blended 1k tokens)\n",
        "        \"fee\": 0.0,\n",
        "        \"overhead\": 0.10,   # Network/Mgmt overhead\n",
        "        \"devops_scale\": 1.0 # Standard Ops load\n",
        "    },\n",
        "    \"Azure Native\": {\n",
        "        \"compute\": 0.096,   # D2s v3\n",
        "        \"gpu\": 0.526,       # NC4as T4\n",
        "        \"storage\": 0.019,   # ADLS Gen2\n",
        "        \"ai_token\": 0.030,  # Azure OpenAI (GPT-4o blended)\n",
        "        \"fee\": 0.0,\n",
        "        \"overhead\": 0.10,\n",
        "        \"devops_scale\": 1.0\n",
        "    },\n",
        "    \"GCP Native\": {\n",
        "        \"compute\": 0.085,   # n2-standard-2\n",
        "        \"gpu\": 0.350,       # L4 GPU\n",
        "        \"storage\": 0.020,   # GCS\n",
        "        \"ai_token\": 0.010,  # Vertex AI (Gemini blended)\n",
        "        \"fee\": 0.0,\n",
        "        \"overhead\": 0.10,\n",
        "        \"devops_scale\": 1.0\n",
        "    },\n",
        "    \"ROSA (AWS)\": {\n",
        "        \"compute\": 0.096,   # Underlying EC2\n",
        "        \"gpu\": 0.526,       # Underlying EC2\n",
        "        \"storage\": 0.023,   # S3\n",
        "        \"ai_token\": 0.000,  # Self-Hosted (Cost is in GPU)\n",
        "        \"fee\": 0.171,       # ROSA Service Fee (Hourly per 4vCPU)\n",
        "        \"overhead\": 0.05,   # Managed service reduces overhead\n",
        "        \"devops_scale\": 1.3 # K8s complexity\n",
        "    },\n",
        "    \"ARO (Azure)\": {\n",
        "        \"compute\": 0.126,   # VM + Fee bundled\n",
        "        \"gpu\": 0.600,       # VM + Fee bundled\n",
        "        \"storage\": 0.019,   # ADLS\n",
        "        \"ai_token\": 0.000,  # Self-Hosted\n",
        "        \"fee\": 0.000,       # Included in unit price often\n",
        "        \"overhead\": 0.05,\n",
        "        \"devops_scale\": 1.3\n",
        "    },\n",
        "    \"Self-Managed OCP\": {\n",
        "        \"compute\": 0.050,   # Bare Metal Amortized\n",
        "        \"gpu\": 0.900,       # Hardware Purchase Amortized\n",
        "        \"storage\": 0.040,   # ODF/Ceph (3x replication cost)\n",
        "        \"ai_token\": 0.000,  # Self-Hosted\n",
        "        \"fee\": 0.060,       # Red Hat Sub per core/hr\n",
        "        \"overhead\": 0.25,   # Power, Cooling, Datacenter\n",
        "        \"devops_scale\": 2.5 # High Ops load\n",
        "    }\n",
        "}\n",
        "\n",
        "# Annual Salaries (Fully Burdened)\n",
        "LABOR_COSTS = {\n",
        "    \"Data Scientist\": 175000,\n",
        "    \"ML Engineer\": 170000,\n",
        "    \"DevOps Engineer\": 165000,\n",
        "    \"Project Manager\": 145000\n",
        "}\n",
        "\n",
        "# --- 2. CALCULATION ENGINE ---\n",
        "\n",
        "def calculate_full_comparison(\n",
        "    candidates, recruiters, salary, hours_saved, retention,\n",
        "    n_ds, n_ml, n_devops, n_pm\n",
        "):\n",
        "    results = []\n",
        "\n",
        "    # -- Sizing Heuristics --\n",
        "    # Storage: 5MB per candidate (Resume + JSON + Logs)\n",
        "    storage_tb = (candidates * 12 * retention * 0.005)\n",
        "\n",
        "    # Compute: 1 vCPU per 50 users (Min 2 nodes)\n",
        "    compute_hours = 730 * max(2, int(recruiters / 50))\n",
        "\n",
        "    # AI Logic:\n",
        "    # Cloud Native = API Cost (Tokens)\n",
        "    # OpenShift = Infrastructure Cost (GPUs)\n",
        "    ai_tokens_k = recruiters * 20 * 30 # 20 queries/day\n",
        "    gpu_hours = 730 * 2 # 2x GPUs for HA Inference (Self-Hosted)\n",
        "\n",
        "    # Business Value (3 Years)\n",
        "    hourly_rate = salary / 2080\n",
        "    monthly_value = recruiters * hours_saved * 4.33 * hourly_rate\n",
        "    total_value_3yr = monthly_value * 36\n",
        "\n",
        "    # -- Cost Loop --\n",
        "    for name, rates in PRICING_DB.items():\n",
        "        # 1. Labor\n",
        "        # Scale DevOps based on platform complexity factor\n",
        "        scaled_ops = n_devops * rates[\"devops_scale\"]\n",
        "        annual_labor = (\n",
        "            (n_ds * LABOR_COSTS[\"Data Scientist\"]) +\n",
        "            (n_ml * LABOR_COSTS[\"ML Engineer\"]) +\n",
        "            (scaled_ops * LABOR_COSTS[\"DevOps Engineer\"]) +\n",
        "            (n_pm * LABOR_COSTS[\"Project Manager\"])\n",
        "        )\n",
        "        labor_3yr = annual_labor * 3\n",
        "\n",
        "        # 2. Infrastructure\n",
        "        c_compute = compute_hours * rates[\"compute\"]\n",
        "\n",
        "        # AI Cost Bifurcation\n",
        "        if \"Native\" in name:\n",
        "            c_ai = ai_tokens_k * rates[\"ai_token\"] # API Cost\n",
        "            gpu_cost_reporting = 0 # No GPU infra, just API opex\n",
        "        else:\n",
        "            c_ai = gpu_hours * rates[\"gpu\"] # GPU Hosting Cost\n",
        "            gpu_cost_reporting = c_ai # Track this as infra\n",
        "\n",
        "        c_storage = (storage_tb * 1000) * rates[\"storage\"]\n",
        "\n",
        "        # OpenShift Fees\n",
        "        c_fees = 0\n",
        "        if rates[\"fee\"] > 0:\n",
        "            nodes = (compute_hours / 730) + (gpu_hours / 730)\n",
        "            c_fees = nodes * 730 * rates[\"fee\"]\n",
        "\n",
        "        # Overhead\n",
        "        raw_infra_monthly = c_compute + c_ai + c_storage + c_fees\n",
        "        total_infra_monthly = raw_infra_monthly * (1 + rates[\"overhead\"])\n",
        "        infra_3yr = total_infra_monthly * 36\n",
        "\n",
        "        # 3. ROI\n",
        "        tco_3yr = labor_3yr + infra_3yr\n",
        "        net_profit = total_value_3yr - tco_3yr\n",
        "        roi = (net_profit / tco_3yr) * 100 if tco_3yr > 0 else 0\n",
        "\n",
        "        # Categorize for Stacked Chart\n",
        "        # \"AI Compute\" is the API cost OR the GPU cost\n",
        "        # \"Base Infra\" is everything else (Compute + Storage + Fees + Overhead)\n",
        "        ai_component_3yr = c_ai * 36\n",
        "        base_infra_3yr = infra_3yr - ai_component_3yr\n",
        "\n",
        "        results.append({\n",
        "            \"Platform\": name,\n",
        "            \"Labor Cost\": round(labor_3yr),\n",
        "            \"Base Infra\": round(base_infra_3yr),\n",
        "            \"AI Compute\": round(ai_component_3yr),\n",
        "            \"Total TCO\": round(tco_3yr),\n",
        "            \"Net Profit\": round(net_profit),\n",
        "            \"ROI %\": round(roi, 1)\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # --- 3. PLOTTING ---\n",
        "\n",
        "    # Figure 1: Stacked Cost Breakdown\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "    platforms = df[\"Platform\"]\n",
        "\n",
        "    # Bottom layer: Labor\n",
        "    p1 = ax1.bar(platforms, df[\"Labor Cost\"], label=\"Labor (DevOps/DS)\", color=\"#2C3E50\", alpha=0.9)\n",
        "    # Middle layer: Base Infra\n",
        "    p2 = ax1.bar(platforms, df[\"Base Infra\"], bottom=df[\"Labor Cost\"], label=\"Base Infra (App/Storage)\", color=\"#2980B9\", alpha=0.9)\n",
        "    # Top layer: AI\n",
        "    p3 = ax1.bar(platforms, df[\"AI Compute\"], bottom=df[\"Labor Cost\"]+df[\"Base Infra\"], label=\"AI (GPU/API)\", color=\"#E74C3C\", alpha=0.9)\n",
        "\n",
        "    ax1.set_title(\"3-Year Cost Breakdown (Where is the money going?)\", fontsize=14)\n",
        "    ax1.set_ylabel(\"Cost (USD)\", fontsize=12)\n",
        "    ax1.legend()\n",
        "    ax1.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Add labels on top of stacks\n",
        "    for i, row in df.iterrows():\n",
        "        total = row[\"Total TCO\"]\n",
        "        ax1.text(i, total, f\"${total/1e6:.1f}M\", ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Figure 2: ROI Comparison\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "    colors = ['green' if x > 0 else 'red' for x in df[\"ROI %\"]]\n",
        "    bars = ax2.bar(platforms, df[\"ROI %\"], color=colors, alpha=0.8)\n",
        "\n",
        "    ax2.set_title(\"3-Year Return on Investment (ROI) %\", fontsize=14)\n",
        "    ax2.set_ylabel(\"ROI %\", fontsize=12)\n",
        "    ax2.axhline(0, color='black', linewidth=0.8)\n",
        "    ax2.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                 f'{height:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Formatted Table for Display\n",
        "    display_df = df.copy()\n",
        "    money_cols = [\"Labor Cost\", \"Base Infra\", \"AI Compute\", \"Total TCO\", \"Net Profit\"]\n",
        "    for col in money_cols:\n",
        "        display_df[col] = display_df[col].apply(lambda x: f\"${x:,.0f}\")\n",
        "    display_df[\"ROI %\"] = display_df[\"ROI %\"].apply(lambda x: f\"{x}%\")\n",
        "\n",
        "    return display_df, fig1, fig2\n",
        "\n",
        "# --- 4. UI CONSTRUCTION ---\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ðŸ¤– Enterprise AI Hiring System: ROI & TCO Comparator\")\n",
        "    gr.Markdown(\"Adjust the sliders below to see how **Scale**, **Labor**, and **Platform Choice** impact your financial bottom line.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 1. Scale & Usage\")\n",
        "            candidates = gr.Slider(10000, 200000, value=50000, step=5000, label=\"Monthly Candidates\")\n",
        "            recruiters = gr.Slider(50, 1000, value=500, step=10, label=\"Internal Users (Recruiters)\")\n",
        "            retention = gr.Slider(1, 7, value=5, label=\"Data Retention (Years)\")\n",
        "\n",
        "            gr.Markdown(\"### 2. Business Value\")\n",
        "            salary = gr.Number(value=90000, label=\"Avg Recruiter Salary ($)\")\n",
        "            hours = gr.Slider(1, 15, value=4, label=\"Hours Saved per Week/Recruiter\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 3. Engineering Team (Base)\")\n",
        "            gr.Markdown(\"*Note: DevOps headcount scales automatically based on platform complexity.*\")\n",
        "            n_ds = gr.Number(value=2, label=\"Data Scientists\")\n",
        "            n_ml = gr.Number(value=2, label=\"ML Engineers\")\n",
        "            n_devops = gr.Number(value=2, label=\"DevOps Engineers (Base)\")\n",
        "            n_pm = gr.Number(value=1, label=\"Project Managers\")\n",
        "\n",
        "            btn = gr.Button(\"ðŸš€ Calculate & Compare\", variant=\"primary\")\n",
        "\n",
        "    # --- TABS FOR OUTPUT ---\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"ðŸ“Š Executive Summary\"):\n",
        "            gr.Markdown(\"### Financial Overview (3-Year Horizon)\")\n",
        "            table_output = gr.DataFrame(label=\"Detailed Financial Comparison\")\n",
        "\n",
        "        with gr.TabItem(\"ðŸ“ˆ Visual Comparison\"):\n",
        "            gr.Markdown(\"### Detailed Cost & ROI Charts\")\n",
        "            with gr.Row():\n",
        "                plot_breakdown = gr.Plot(label=\"Cost Breakdown (Stacked)\")\n",
        "                plot_roi = gr.Plot(label=\"ROI Comparison\")\n",
        "\n",
        "    # Event Listener\n",
        "    btn.click(\n",
        "        calculate_full_comparison,\n",
        "        inputs=[candidates, recruiters, salary, hours, retention, n_ds, n_ml, n_devops, n_pm],\n",
        "        outputs=[table_output, plot_breakdown, plot_roi]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    }
  ]
}